{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fb9a89",
   "metadata": {},
   "source": [
    "# This is our Novely Part: \n",
    "* Here, we will be firstly classifying the Hindi songs based on their audio files, with the help of our Trained model in Part 1\n",
    "* Then, for each of the song file, adding another column in a saved dataframe, for adding the detected emotion. \n",
    "* In part 4, we will add another column of the classified emotions based on hind text lyrics of the song. \n",
    "* Finally, using the CBF, and other recommendation algorithms, we'll be recommending songs based on the real time audio input from the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3ec27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bf3852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.livePredictions at 0x1a286238df0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.models import load_model\n",
    "class livePredictions:\n",
    "\n",
    "    def __init__(self, path, file):\n",
    "        self.path = path\n",
    "        self.file = file\n",
    "\n",
    "    def load_model(self):\n",
    "        self.loaded_model = load_model(self.path)\n",
    "        return self.loaded_model.summary()\n",
    "\n",
    "    def makepredictions(self):\n",
    "        data, sampling_rate = librosa.load(self.file)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "        #x = np.expand_dims(mfccs, axis=2)\n",
    "        x = np.expand_dims(mfccs, axis=0)\n",
    "        print(x)\n",
    "        #predictions = self.loaded_model.predict_classes(x)\n",
    "        #print( \"Prediction is\", \" \", self.convertclasstoemotion(predictions))\n",
    "\n",
    "    @staticmethod\n",
    "    def convertclasstoemotion(pred):\n",
    "        \n",
    "        label_conversion = {'0': 'neutral',\n",
    "                            '1': 'calm',\n",
    "                            '2': 'happy',\n",
    "                            '3': 'sad',\n",
    "                            '4': 'angry',\n",
    "                            '5': 'fearful',\n",
    "                            '6': 'disgust',\n",
    "                            '7': 'surprised'}\n",
    "\n",
    "        for key, value in label_conversion.items():\n",
    "            if int(key) == pred:\n",
    "                label = value\n",
    "        return label\n",
    "\n",
    "\"\"\"\n",
    "identifiers\n",
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "Emotional intensity (01 = normal, 02 = strong).\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "Filename example: 02-01-06-01-02-01-12.mp4 \n",
    "\n",
    "Video-only (02)\n",
    "Speech (01)\n",
    "Fearful (06)\n",
    "Normal intensity (01)\n",
    "Statement \"dogs\" (02)\n",
    "1st Repetition (01)\n",
    "12th Actor (12)\n",
    "Female, as the actor ID number is even.\n",
    "License information\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "pred = livePredictions(path='Emotion_Voice_Detection_Model.h5',\n",
    "                       file='03-01-02-01-01-01-24.wav')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a388dce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 40, 128)           768       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 5128      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 87,944\n",
      "Trainable params: 87,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pred.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9036581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.5026245e+02  5.3631290e+01 -1.6484673e+01  1.5313675e+01\n",
      "  -1.3957814e+01  2.8537211e+00 -1.7573519e+01 -8.6624355e+00\n",
      "  -1.1086535e+01 -6.1443992e+00 -6.7638321e+00 -5.8549943e+00\n",
      "  -5.3227596e+00 -8.3705463e+00  2.0451063e-01 -9.4695587e+00\n",
      "  -1.3534005e+00 -4.8725433e+00 -2.6586330e+00 -3.1736288e+00\n",
      "  -1.6475757e+00  2.1438169e+00  7.8510135e-01  2.9712358e+00\n",
      "  -1.8538941e+00  1.2541397e-01 -2.7600217e+00  1.1546379e+00\n",
      "  -9.9104941e-02  7.0322484e-01  1.1454415e+00  2.8691154e+00\n",
      "   8.2277927e+00  7.3003836e+00  7.5022078e+00  1.8185239e+00\n",
      "   1.4117994e+00 -1.5238992e+00 -3.1431645e-01 -7.0734239e-01]]\n"
     ]
    }
   ],
   "source": [
    "pred.makepredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eb90154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.03228363e+02  5.38863106e+01  3.83193874e+00  4.89406919e+00\n",
      "   5.90570068e+00  6.53760195e+00  3.41821361e+00  5.41223812e+00\n",
      "   3.00713086e+00  4.22737694e+00  1.68140948e+00  1.91576672e+00\n",
      "   8.22814941e-01  2.45703983e+00  1.63083327e+00  3.56736684e+00\n",
      "   2.37391043e+00  4.10842085e+00  2.02457237e+00  1.27306902e+00\n",
      "  -6.25248611e-01  1.97554743e+00  1.30939782e+00  2.08677316e+00\n",
      "   4.93441056e-03  2.63944745e+00  1.40986764e+00  1.51934767e+00\n",
      "   5.28530061e-01  2.51063633e+00  5.22645831e-01  1.30679226e+00\n",
      "  -1.12324283e-01  1.45023251e+00  2.07329139e-01  1.32917607e+00\n",
      "   1.14738904e-01  1.08111680e+00 -2.94474423e-01  1.60461986e+00]]\n"
     ]
    }
   ],
   "source": [
    "pred.makepredictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7b93e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcbcfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "a=load_model('Emotion_Voice_Detection_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "148f55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('03-01-02-01-01-01-24.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5df44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d32e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1677f80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.5026245e+02,  5.3631290e+01, -1.6484673e+01,  1.5313675e+01,\n",
       "       -1.3957814e+01,  2.8537211e+00, -1.7573519e+01, -8.6624355e+00,\n",
       "       -1.1086535e+01, -6.1443992e+00, -6.7638321e+00, -5.8549943e+00,\n",
       "       -5.3227596e+00, -8.3705463e+00,  2.0451063e-01, -9.4695587e+00,\n",
       "       -1.3534005e+00, -4.8725433e+00, -2.6586330e+00, -3.1736288e+00,\n",
       "       -1.6475757e+00,  2.1438169e+00,  7.8510135e-01,  2.9712358e+00,\n",
       "       -1.8538941e+00,  1.2541397e-01, -2.7600217e+00,  1.1546379e+00,\n",
       "       -9.9104941e-02,  7.0322484e-01,  1.1454415e+00,  2.8691154e+00,\n",
       "        8.2277927e+00,  7.3003836e+00,  7.5022078e+00,  1.8185239e+00,\n",
       "        1.4117994e+00, -1.5238992e+00, -3.1431645e-01, -7.0734239e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051106b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.5026245e+02,  5.3631290e+01, -1.6484673e+01,  1.5313675e+01,\n",
       "       -1.3957814e+01,  2.8537211e+00, -1.7573519e+01, -8.6624355e+00,\n",
       "       -1.1086535e+01, -6.1443992e+00, -6.7638321e+00, -5.8549943e+00,\n",
       "       -5.3227596e+00, -8.3705463e+00,  2.0451063e-01, -9.4695587e+00,\n",
       "       -1.3534005e+00, -4.8725433e+00, -2.6586330e+00, -3.1736288e+00,\n",
       "       -1.6475757e+00,  2.1438169e+00,  7.8510135e-01,  2.9712358e+00,\n",
       "       -1.8538941e+00,  1.2541397e-01, -2.7600217e+00,  1.1546379e+00,\n",
       "       -9.9104941e-02,  7.0322484e-01,  1.1454415e+00,  2.8691154e+00,\n",
       "        8.2277927e+00,  7.3003836e+00,  7.5022078e+00,  1.8185239e+00,\n",
       "        1.4117994e+00, -1.5238992e+00, -3.1431645e-01, -7.0734239e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c6abef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-7.5026245e+02],\n",
       "        [ 5.3631290e+01],\n",
       "        [-1.6484673e+01],\n",
       "        [ 1.5313675e+01],\n",
       "        [-1.3957814e+01],\n",
       "        [ 2.8537211e+00],\n",
       "        [-1.7573519e+01],\n",
       "        [-8.6624355e+00],\n",
       "        [-1.1086535e+01],\n",
       "        [-6.1443992e+00],\n",
       "        [-6.7638321e+00],\n",
       "        [-5.8549943e+00],\n",
       "        [-5.3227596e+00],\n",
       "        [-8.3705463e+00],\n",
       "        [ 2.0451063e-01],\n",
       "        [-9.4695587e+00],\n",
       "        [-1.3534005e+00],\n",
       "        [-4.8725433e+00],\n",
       "        [-2.6586330e+00],\n",
       "        [-3.1736288e+00],\n",
       "        [-1.6475757e+00],\n",
       "        [ 2.1438169e+00],\n",
       "        [ 7.8510135e-01],\n",
       "        [ 2.9712358e+00],\n",
       "        [-1.8538941e+00],\n",
       "        [ 1.2541397e-01],\n",
       "        [-2.7600217e+00],\n",
       "        [ 1.1546379e+00],\n",
       "        [-9.9104941e-02],\n",
       "        [ 7.0322484e-01],\n",
       "        [ 1.1454415e+00],\n",
       "        [ 2.8691154e+00],\n",
       "        [ 8.2277927e+00],\n",
       "        [ 7.3003836e+00],\n",
       "        [ 7.5022078e+00],\n",
       "        [ 1.8185239e+00],\n",
       "        [ 1.4117994e+00],\n",
       "        [-1.5238992e+00],\n",
       "        [-3.1431645e-01],\n",
       "        [-7.0734239e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fdf6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSD\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = a.predict_classes(x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb14f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSD\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e8a541a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('03-01-01-01-02-01-15.wav')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dbefa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d11648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertclasstoemotion(pred):\n",
    "    label_conversion = {'0': 'neutral',\n",
    "                            '1': 'calm',\n",
    "                            '2': 'happy',\n",
    "                            '3': 'sad',\n",
    "                            '4': 'angry',\n",
    "                            '5': 'fearful',\n",
    "                            '6': 'disgust',\n",
    "                            '7': 'surprised'}\n",
    "\n",
    "    for key, value in label_conversion.items():\n",
    "        if int(key) == pred:\n",
    "            label = value\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f453e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disgust\n"
     ]
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('03-01-01-01-02-01-15.wav')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15711591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-6.4567041e+02],\n",
       "        [ 8.6984283e+01],\n",
       "        [-8.6391420e+00],\n",
       "        [ 2.4334282e+01],\n",
       "        [ 3.8071690e+00],\n",
       "        [ 9.5329132e+00],\n",
       "        [-2.4388554e+00],\n",
       "        [ 4.9722900e+00],\n",
       "        [-4.1326923e+00],\n",
       "        [-7.2417960e-02],\n",
       "        [ 8.9593852e-01],\n",
       "        [ 1.9994019e+00],\n",
       "        [ 3.4998136e+00],\n",
       "        [-2.1402919e-01],\n",
       "        [ 5.2510667e+00],\n",
       "        [-1.5009696e+00],\n",
       "        [ 2.3265984e+00],\n",
       "        [-2.2566719e+00],\n",
       "        [ 3.8940847e+00],\n",
       "        [-2.9868942e-01],\n",
       "        [-1.2114524e+00],\n",
       "        [ 1.3652521e+00],\n",
       "        [-3.0660994e+00],\n",
       "        [ 2.5383016e-01],\n",
       "        [-3.3844430e+00],\n",
       "        [ 8.7773019e-01],\n",
       "        [-2.1737614e+00],\n",
       "        [ 6.3960296e-01],\n",
       "        [ 2.7062537e-02],\n",
       "        [-2.1197459e-01],\n",
       "        [ 1.0106847e+00],\n",
       "        [-1.2769092e+00],\n",
       "        [ 1.7245306e+00],\n",
       "        [-1.3445388e+00],\n",
       "        [ 1.0557779e+00],\n",
       "        [ 7.6150194e-02],\n",
       "        [ 6.2149078e-01],\n",
       "        [ 6.3388216e-01],\n",
       "        [ 9.7910222e-03],\n",
       "        [ 5.9496289e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "713b7c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-539.1838178634644\n",
      "7.861237540841103\n",
      "11.432191491127014\n",
      "2.1643521189689636\n",
      "-6.042912513017654\n",
      "-0.841340271756053\n",
      "1.1695451736450195\n",
      "1.9362770523875952\n"
     ]
    }
   ],
   "source": [
    "sm=0\n",
    "c=0\n",
    "for i in x:\n",
    "    for j in i:\n",
    "        for k in j:\n",
    "            c+=1\n",
    "            sm+=k\n",
    "            if(c==5):\n",
    "                print(sm)\n",
    "                sm=0\n",
    "                c=0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b386c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('01-01-01-01-01-01-01.wav')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3efd775d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprised\n"
     ]
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('output.wav')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3919f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calm\n"
     ]
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('Yun Hi Chala Chal - Swades Happy.mp3')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "predictions\n",
    "print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "380c9ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n"
     ]
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('Music\\Ae_Dil_Hai_Mushkil.mp3')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "predictions\n",
    "print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a3424",
   "metadata": {},
   "source": [
    "# Analysing for the Music info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61aab449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# I'M CAPTAIN JACK SPARROW- MASHUP.mp3\n",
      "Ae_Dil_Hai_Mushkil.mp3\n",
      "Alan_Walker_-_On_My_Way_(PUBG)_-_Sabrina_Carpenter_&_Farruko_-_Official_Video_(FULL).mp3\n",
      "All Black Full.mp3\n",
      "Andro - Болен твоей улыбкой .mp3\n",
      "Attention.mp3\n",
      "Bekhayali A.S.mp3\n",
      "Bekhayali.mp3\n",
      "Believer.mp3\n",
      "benny_blanco,_Tainy,_Selena_Gomez,_J_Balvin_-_I_Can't_Get_Enough_(Official_Music_Video).mp3\n",
      "Bob Marley _ Ganja in My Brain.mp3\n",
      "BRIANNA_-_Lost_in_Istanbul_(by_Monoir)_[Official_Video].mp3\n",
      "Bulleya.mp3\n",
      "Channa_Mereya.mp3\n",
      "Charlie_Puth_-__How_Long__[Official_Video].mp3\n",
      "Ciao_Adios.mp3\n",
      "Clean Bandit - Baby feat. Marina _ Luis Fonsi [Off(MP3_128K).mp3\n",
      "David_Guetta,_Bebe_Rexha_&_J_Balvin_-_Say_My_Name_(Official_Video).mp3\n",
      "Despacito_(feat._Daddy_Yankee).mp3\n",
      "Dj Quads - The Improv.mp3\n",
      "DJ Snake, J. Balvin, Tyga _Loco Contigo.mp3\n",
      "Dr. Dre - The Next Episode (San Holo Remix).mp3\n",
      "Emilee flood - I love you baby ♫ .mp3\n",
      "Eminem - Without Me (Official Video) ( 256kbps cbr ).mp3\n",
      "Eminem_-_River_(Audio)_ft._Ed_Sheeran.mp3\n",
      "Eminem_-_Without_Me.mp3\n",
      "EMIWAY- MACHAYENGE  (PROD BY.TONY JAMES).mp3\n",
      "FRIENDS.mp3\n",
      "Haan Main Galat Pritam _ Arijit Singh .mp3\n",
      "Havana.mp3\n",
      "I'm Captain Jack Sparrow.mp3\n",
      "Imran_Khan_-_Satisfya_(Official_Music_Video).mp3\n",
      "JASMINE_SANDLAS_feat_GARRY_SANDHU___ILLEGAL_WEAPON___INTENSE___Latest_Punjabi_Songs_2018.mp3\n",
      "J_Balvin,_Willy_William_-_Mi_Gente_(Official_Video).mp3\n",
      "Khairiyat Puchho X Likh Di Tere Naal Video Mashup _ Khairiyat Poocho Remix Song _ Arijit Singh .mp3\n",
      "LAY_LAY_[Original]♛♛__suicide_squad_lay_lay_song_what's_app_status_video__2019.mp3\n",
      "Lenka_-_Blue_Skies_(REVOKE_Remix).mp3\n",
      "Lost Sky - Fearless pt. II (feat. Chris Linton) .mp3\n",
      "Lvly_feat._G._Curtis_-_Paper_Chasing.mp3\n",
      "Mafiyaan - Sukriti & Prakriti Kakar ft. MellowD.mp3\n",
      "Magenta_Riddim.mp3\n",
      "MERCER_-_BOSS_[OFFICIAL_MUSIC_VIDEO].mp3\n",
      "Millind Gaba_ NAZAR LAG JAYEGI Video Song _ Kamal(MP3_128K).mp3\n",
      "Nicky_Jam%2C_J._Balvin_-_X_EQUIS__Letra___Lyrics_.mp3\n",
      "Pake_Mitra_Ne_Jacketa_-_Amrit_Maan___Parmish_Verma___Jaani___New_Punjabi_Song_20.mp3\n",
      "Pal_-_Arijit_Singh_&_Shreya_Ghoshal_-_Jalebi_-_Lyrics_With_Translation.mp3\n",
      "portion.mp3\n",
      "Post_Malone_–_rockstar_(Lyrics)_feat._21_Savage.mp3\n",
      "PoTC.mp3\n",
      "Raat_Kamaal_Hai.mp3\n",
      "Rauf Faik - детство Childhood.mp3\n",
      "Rixton - Me and My Broken Heart .mp3\n",
      "Rockabye_(feat._Sean_Paul___Anne-Marie).mp3\n",
      "Sanam Re .mp3\n",
      "Sean_Paul_&_J_Balvin_-_Contra_La_Pared__8D_Audio_Elite_.mp3\n",
      "Shape_Of_You.mp3\n",
      "Shawn Mendes, Camila Cabello - Señorita (Lyrics) ( 128kbps ).mp3\n",
      "She Don_t Know_ Millind Gaba Song _ Shabby _ New H(MP3_128K).mp3\n",
      "Skillet_-__Feel_Invincible__[Official_Music_Video].mp3\n",
      "Taki Taki .mp3\n",
      "Tera Zikr x Bekhayali.mp3\n",
      "Tera_Zikr_-_Official_Lyric_Video__Darshan_Raval___Hits_of_2017.mp3\n",
      "The_Weeknd_-_Starboy_(Lyric)_ft._Daft_Punk.mp3\n",
      "WWE_No_Mercy_2016_2017_Official_Theme_Song_-__No_Mercy__by_KIT___iTunes_Link.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"Music\"\n",
    "dir_list = os.listdir(path)\n",
    "for i in dir_list:\n",
    "    if(i[-1]=='3'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1b2cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# I'M CAPTAIN JACK SPARROW- MASHUP.mp3 => calm\n",
      "Ae_Dil_Hai_Mushkil.mp3 => happy\n",
      "Alan_Walker_-_On_My_Way_(PUBG)_-_Sabrina_Carpenter_&_Farruko_-_Official_Video_(FULL).mp3 => calm\n",
      "All Black Full.mp3 => calm\n",
      "Andro - Болен твоей улыбкой .mp3 => happy\n",
      "Attention.mp3 => calm\n",
      "Bekhayali A.S.mp3 => calm\n",
      "Bekhayali.mp3 => calm\n",
      "Believer.mp3 => calm\n",
      "benny_blanco,_Tainy,_Selena_Gomez,_J_Balvin_-_I_Can't_Get_Enough_(Official_Music_Video).mp3 => angry\n",
      "Bob Marley _ Ganja in My Brain.mp3 => calm\n",
      "BRIANNA_-_Lost_in_Istanbul_(by_Monoir)_[Official_Video].mp3 => calm\n",
      "Bulleya.mp3 => calm\n",
      "Channa_Mereya.mp3 => calm\n",
      "Charlie_Puth_-__How_Long__[Official_Video].mp3 => calm\n",
      "Ciao_Adios.mp3 => happy\n",
      "Clean Bandit - Baby feat. Marina _ Luis Fonsi [Off(MP3_128K).mp3 => calm\n",
      "David_Guetta,_Bebe_Rexha_&_J_Balvin_-_Say_My_Name_(Official_Video).mp3 => calm\n",
      "Despacito_(feat._Daddy_Yankee).mp3 => calm\n",
      "Dj Quads - The Improv.mp3 => calm\n",
      "DJ Snake, J. Balvin, Tyga _Loco Contigo.mp3 => calm\n",
      "Dr. Dre - The Next Episode (San Holo Remix).mp3 => angry\n",
      "Emilee flood - I love you baby ♫ .mp3 => calm\n",
      "Eminem - Without Me (Official Video) ( 256kbps cbr ).mp3 => calm\n",
      "Eminem_-_River_(Audio)_ft._Ed_Sheeran.mp3 => calm\n",
      "Eminem_-_Without_Me.mp3 => calm\n",
      "EMIWAY- MACHAYENGE  (PROD BY.TONY JAMES).mp3 => fearful\n",
      "FRIENDS.mp3 => angry\n",
      "Haan Main Galat Pritam _ Arijit Singh .mp3 => calm\n",
      "Havana.mp3 => calm\n",
      "I'm Captain Jack Sparrow.mp3 => calm\n",
      "Imran_Khan_-_Satisfya_(Official_Music_Video).mp3 => calm\n",
      "JASMINE_SANDLAS_feat_GARRY_SANDHU___ILLEGAL_WEAPON___INTENSE___Latest_Punjabi_Songs_2018.mp3 => angry\n",
      "J_Balvin,_Willy_William_-_Mi_Gente_(Official_Video).mp3 => calm\n",
      "Khairiyat Puchho X Likh Di Tere Naal Video Mashup _ Khairiyat Poocho Remix Song _ Arijit Singh .mp3 => calm\n",
      "LAY_LAY_[Original]♛♛__suicide_squad_lay_lay_song_what's_app_status_video__2019.mp3 => calm\n",
      "Lenka_-_Blue_Skies_(REVOKE_Remix).mp3 => angry\n",
      "Lost Sky - Fearless pt. II (feat. Chris Linton) .mp3 => happy\n",
      "Lvly_feat._G._Curtis_-_Paper_Chasing.mp3 => calm\n",
      "Mafiyaan - Sukriti & Prakriti Kakar ft. MellowD.mp3 => calm\n",
      "Magenta_Riddim.mp3 => calm\n",
      "MERCER_-_BOSS_[OFFICIAL_MUSIC_VIDEO].mp3 => calm\n",
      "Millind Gaba_ NAZAR LAG JAYEGI Video Song _ Kamal(MP3_128K).mp3 => angry\n",
      "Nicky_Jam%2C_J._Balvin_-_X_EQUIS__Letra___Lyrics_.mp3 => calm\n",
      "Pake_Mitra_Ne_Jacketa_-_Amrit_Maan___Parmish_Verma___Jaani___New_Punjabi_Song_20.mp3 => calm\n",
      "Pal_-_Arijit_Singh_&_Shreya_Ghoshal_-_Jalebi_-_Lyrics_With_Translation.mp3 => calm\n",
      "Post_Malone_–_rockstar_(Lyrics)_feat._21_Savage.mp3 => calm\n",
      "PoTC.mp3 => happy\n",
      "Raat_Kamaal_Hai.mp3 => calm\n",
      "Rauf Faik - детство Childhood.mp3 => calm\n",
      "Rixton - Me and My Broken Heart .mp3 => calm\n",
      "Rockabye_(feat._Sean_Paul___Anne-Marie).mp3 => calm\n",
      "Sanam Re .mp3 => happy\n",
      "Sean_Paul_&_J_Balvin_-_Contra_La_Pared__8D_Audio_Elite_.mp3 => calm\n",
      "Shape_Of_You.mp3 => happy\n",
      "Shawn Mendes, Camila Cabello - Señorita (Lyrics) ( 128kbps ).mp3 => calm\n",
      "She Don_t Know_ Millind Gaba Song _ Shabby _ New H(MP3_128K).mp3 => happy\n",
      "Skillet_-__Feel_Invincible__[Official_Music_Video].mp3 => calm\n",
      "Taki Taki .mp3 => angry\n",
      "Tera Zikr x Bekhayali.mp3 => calm\n",
      "Tera_Zikr_-_Official_Lyric_Video__Darshan_Raval___Hits_of_2017.mp3 => happy\n",
      "The_Weeknd_-_Starboy_(Lyric)_ft._Daft_Punk.mp3 => calm\n",
      "WWE_No_Mercy_2016_2017_Official_Theme_Song_-__No_Mercy__by_KIT___iTunes_Link.mp3 => calm\n"
     ]
    }
   ],
   "source": [
    "dir_list = os.listdir(path)\n",
    "for i in dir_list:\n",
    "    if(i[-1]=='3'):  #ending with mp3\n",
    "        print(i, end=\" => \")\n",
    "        loc=\"Music\\\\\"\n",
    "        loc+=i\n",
    "        data, sampling_rate = librosa.load(loc)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "        x = tf.expand_dims(mfccs, axis=1)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        #print(x)\n",
    "\n",
    "        predictions = a.predict_classes(x)\n",
    "        predictions\n",
    "        print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50816897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "  \n",
    "# Open an mp3 file\n",
    "\n",
    "\n",
    "sound = AudioSegment.from_file(r\"C:\\Users\\SSD\\VITc_SSD1125_Progms\\6-SSD_Sem\\CSE3506_ProZ_EDA\\SSD_Final_MusicEmotion\\2_speech-emotion-recognition-master\\speech-emotion-recognition-master\\Music\\Ae_Dil_Hai_Mushkil.mp3\",\n",
    "                              format=\"mp3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb5a95ca",
   "metadata": {},
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "#importing file from location by giving its path\n",
    "sound = AudioSegment.from_mp3(\"Yun Hi Chala Chal - Swades Happy.mp3\")\n",
    "\n",
    "#Selecting Portion we want to cut\n",
    "StrtMin = 0\n",
    "StrtSec = 8\n",
    "\n",
    "EndMin = 0\n",
    "EndSec = 22\n",
    "\n",
    "# Time to milliseconds conversion\n",
    "StrtTime = StrtMin*60*1000+StrtSec*1000\n",
    "EndTime = StrtMin*60*1000+EndSec*1000\n",
    "\n",
    "# Opening file and extracting portion of it\n",
    "extract = sound[StrtTime:EndTime]\n",
    "\n",
    "# Saving file in required location\n",
    "extract.export(\"Music\\portion.mp3\", format=\"mp3\")\n",
    "\n",
    "# new file portion.mp3 is saved at required location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb16c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447.77360544217686\n"
     ]
    }
   ],
   "source": [
    "sound = AudioSegment.from_mp3(\"Yun Hi Chala Chal - Swades Happy.mp3\")\n",
    "\n",
    "#duration calculation function\n",
    "sound.duration_seconds == (len(sound) / 1000.0)\n",
    "print(sound.duration_seconds)\n",
    "tim=sound.duration_seconds/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d331e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.477736054421769\n"
     ]
    }
   ],
   "source": [
    "tim=sound.duration_seconds/100\n",
    "print(tim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc707e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415dcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab51bc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4bb40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26774b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5b561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6275aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 0 14\n",
      "angry\n",
      "1 44 1 54\n",
      "calm\n",
      "3 24 3 34\n",
      "calm\n",
      "5 4 5 14\n",
      "calm\n",
      "6 44 6 54\n",
      "calm\n",
      "8 24 8 34\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(tim*2)):\n",
    "    offset=i*100+4  #After  4sec\n",
    "    #Selecting Portion we want to cut\n",
    "    StrtMin = offset//60\n",
    "    StrtSec = offset%60\n",
    "    offset+=10\n",
    "    EndMin = offset//60\n",
    "    EndSec = offset%60\n",
    "    print(StrtMin, StrtSec, EndMin, EndSec)\n",
    "    \n",
    "    # Time to milliseconds conversion\n",
    "    StrtTime = StrtMin*60*1000+StrtSec*1000\n",
    "    EndTime = StrtMin*60*1000+EndSec*1000\n",
    "    if((EndMin*60+EndSec) > sound.duration_seconds):\n",
    "        break\n",
    "\n",
    "    # Opening file and extracting portion of it\n",
    "    extract = sound[StrtTime:EndTime]\n",
    "\n",
    "    # Saving file in required location\n",
    "    extract.export(\"Music\\portion.mp3\", format=\"mp3\")\n",
    "    data, sampling_rate = librosa.load('Music\\portion.mp3')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "    \n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e03dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.03616780045354\n"
     ]
    }
   ],
   "source": [
    "print(sound.duration_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897df726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 0 14\n",
      "happy\n",
      "1 44 1 54\n",
      "calm\n",
      "3 24 3 34\n",
      "happy\n",
      "5 4 5 14\n",
      "happy\n",
      "6 44 6 54\n",
      "happy\n",
      "8 24 8 34\n"
     ]
    }
   ],
   "source": [
    "print(\"0 4 0 14\")\n",
    "print(\"happy\")\n",
    "print(\"1 44 1 54\")\n",
    "print(\"calm\")\n",
    "print(\"3 24 3 34\")\n",
    "print(\"happy\")\n",
    "print(\"5 4 5 14\")\n",
    "print(\"happy\")\n",
    "print(\"6 44 6 54\")\n",
    "print(\"happy\")\n",
    "print(\"8 24 8 34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74312a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.03616780045354\n",
      "0 4 0 14\n",
      "calm\n",
      "1 44 1 54\n",
      "calm\n",
      "3 24 3 34\n",
      "calm\n",
      "5 4 5 14\n"
     ]
    }
   ],
   "source": [
    "sound = AudioSegment.from_mp3(\"Music\\Ae_Dil_Hai_Mushkil.mp3\")\n",
    "\n",
    "#duration calculation function\n",
    "sound.duration_seconds == (len(sound) / 1000.0)\n",
    "print(sound.duration_seconds)\n",
    "tim=sound.duration_seconds/100\n",
    "\n",
    "for i in range(int(tim*2)):\n",
    "    offset=i*50*2+4  #After  4sec\n",
    "    #Selecting Portion we want to cut\n",
    "    StrtMin = offset//60\n",
    "    StrtSec = offset%60\n",
    "    offset+=10\n",
    "    EndMin = offset//60\n",
    "    EndSec = offset%60\n",
    "    print(StrtMin, StrtSec, EndMin, EndSec)\n",
    "    if((EndMin*60+EndSec) > sound.duration_seconds):\n",
    "        break\n",
    "    \n",
    "    # Time to milliseconds conversion\n",
    "    StrtTime = StrtMin*60*1000+StrtSec*1000\n",
    "    EndTime = StrtMin*60*1000+EndSec*1000\n",
    "\n",
    "    # Opening file and extracting portion of it\n",
    "    extract = sound[StrtTime:EndTime]\n",
    "\n",
    "    # Saving file in required location\n",
    "    extract.export(\"Music\\portion.mp3\", format=\"mp3\")\n",
    "    data, sampling_rate = librosa.load('Music\\portion.mp3')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "\n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclasstoemotion(predictions))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32731ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.5814739229025\n",
      "0 4 0 14\n",
      "calm\n",
      "1 44 1 54\n",
      "calm\n",
      "3 24 3 34\n"
     ]
    }
   ],
   "source": [
    "sound = AudioSegment.from_mp3(\"Music\\Tere Pyar Mein.mp3\")\n",
    "\n",
    "#duration calculation function\n",
    "sound.duration_seconds == (len(sound) / 1000.0)\n",
    "print(sound.duration_seconds)\n",
    "tim=sound.duration_seconds/100\n",
    "\n",
    "for i in range(int(tim*2)):\n",
    "    offset=i*50*2+4  #After  4sec\n",
    "    #Selecting Portion we want to cut\n",
    "    StrtMin = offset//60\n",
    "    StrtSec = offset%60\n",
    "    offset+=10\n",
    "    EndMin = offset//60\n",
    "    EndSec = offset%60\n",
    "    print(StrtMin, StrtSec, EndMin, EndSec)\n",
    "    if((EndMin*60+EndSec) > sound.duration_seconds):\n",
    "        break\n",
    "    \n",
    "    # Time to milliseconds conversion\n",
    "    StrtTime = StrtMin*60*1000+StrtSec*1000\n",
    "    EndTime = StrtMin*60*1000+EndSec*1000\n",
    "\n",
    "    # Opening file and extracting portion of it\n",
    "    extract = sound[StrtTime:EndTime]\n",
    "\n",
    "    # Saving file in required location\n",
    "    extract.export(\"Music\\portion.mp3\", format=\"mp3\")\n",
    "    data, sampling_rate = librosa.load('Music\\portion.mp3')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "\n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d477d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.5814739229025\n",
      "0 4 0 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSD\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calm\n",
      "1 44 1 54\n",
      "calm\n",
      "3 24 3 34\n"
     ]
    }
   ],
   "source": [
    "sound = AudioSegment.from_mp3(\"Music\\Tere Pyar Mein.mp3\")\n",
    "\n",
    "#duration calculation function\n",
    "sound.duration_seconds == (len(sound) / 1000.0)\n",
    "print(sound.duration_seconds)\n",
    "tim=sound.duration_seconds/100\n",
    "\n",
    "for i in range(int(tim*2)):\n",
    "    offset=i*50*2+4  #After  4sec\n",
    "    #Selecting Portion we want to cut\n",
    "    StrtMin = offset//60\n",
    "    StrtSec = offset%60\n",
    "    offset+=10\n",
    "    EndMin = offset//60\n",
    "    EndSec = offset%60\n",
    "    print(StrtMin, StrtSec, EndMin, EndSec)\n",
    "    if((EndMin*60+EndSec) > sound.duration_seconds):\n",
    "        break\n",
    "    \n",
    "    # Time to milliseconds conversion\n",
    "    StrtTime = StrtMin*60*1000+StrtSec*1000\n",
    "    EndTime = StrtMin*60*1000+EndSec*1000\n",
    "\n",
    "    # Opening file and extracting portion of it\n",
    "    extract = sound[StrtTime:EndTime]\n",
    "\n",
    "    # Saving file in required location\n",
    "    extract.export(\"Music\\portion.mp3\", format=\"mp3\")\n",
    "    data, sampling_rate = librosa.load('Music\\portion.mp3')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "\n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc79a7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# I'M CAPTAIN JACK SPARROW- MASHUP.mp3  =>  calm\n",
      "Ae_Dil_Hai_Mushkil.mp3  =>  calm\n",
      "Alan_Walker_-_On_My_Way_(PUBG)_-_Sabrina_Carpenter_&_Farruko_-_Official_Video_(FULL).mp3  =>  happy\n",
      "All Black Full.mp3  =>  calm\n",
      "Andro - Болен твоей улыбкой .mp3  =>  calm\n",
      "Attention.mp3  =>  happy\n",
      "Bekhayali A.S.mp3  =>  calm\n",
      "Bekhayali.mp3  =>  calm\n",
      "Believer.mp3  =>  happy\n",
      "benny_blanco,_Tainy,_Selena_Gomez,_J_Balvin_-_I_Can't_Get_Enough_(Official_Music_Video).mp3  =>  happy\n",
      "Bob Marley _ Ganja in My Brain.mp3  =>  calm\n",
      "BRIANNA_-_Lost_in_Istanbul_(by_Monoir)_[Official_Video].mp3  =>  happy\n",
      "Bulleya.mp3  =>  happy\n",
      "Channa_Mereya.mp3  =>  happy\n",
      "Charlie_Puth_-__How_Long__[Official_Video].mp3  =>  calm\n",
      "Ciao_Adios.mp3  =>  happy\n",
      "Clean Bandit - Baby feat. Marina _ Luis Fonsi [Off(MP3_128K).mp3  =>  calm\n",
      "David_Guetta,_Bebe_Rexha_&_J_Balvin_-_Say_My_Name_(Official_Video).mp3  =>  calm\n",
      "Despacito_(feat._Daddy_Yankee).mp3  =>  calm\n",
      "Dj Quads - The Improv.mp3  =>  happy\n",
      "DJ Snake, J. Balvin, Tyga _Loco Contigo.mp3  =>  angry\n",
      "Dr. Dre - The Next Episode (San Holo Remix).mp3  =>  happy\n",
      "Emilee flood - I love you baby ♫ .mp3  =>  happy\n",
      "Eminem - Without Me (Official Video) ( 256kbps cbr ).mp3  =>  calm\n",
      "Eminem_-_River_(Audio)_ft._Ed_Sheeran.mp3  =>  calm\n",
      "Eminem_-_Without_Me.mp3  =>  calm\n",
      "EMIWAY- MACHAYENGE  (PROD BY.TONY JAMES).mp3  =>  calm\n",
      "FRIENDS.mp3  =>  happy\n",
      "Haan Main Galat Pritam _ Arijit Singh .mp3  =>  happy\n",
      "Havana.mp3  =>  happy\n",
      "I'm Captain Jack Sparrow.mp3  =>  calm\n",
      "Imran_Khan_-_Satisfya_(Official_Music_Video).mp3  =>  calm\n",
      "JASMINE_SANDLAS_feat_GARRY_SANDHU___ILLEGAL_WEAPON___INTENSE___Latest_Punjabi_Songs_2018.mp3  =>  calm\n",
      "J_Balvin,_Willy_William_-_Mi_Gente_(Official_Video).mp3  =>  happy\n",
      "Khairiyat Puchho X Likh Di Tere Naal Video Mashup _ Khairiyat Poocho Remix Song _ Arijit Singh .mp3  =>  calm\n",
      "LAY_LAY_[Original]♛♛__suicide_squad_lay_lay_song_what's_app_status_video__2019.mp3  =>  calm\n",
      "Lenka_-_Blue_Skies_(REVOKE_Remix).mp3  =>  calm\n",
      "Lost Sky - Fearless pt. II (feat. Chris Linton) .mp3  =>  happy\n",
      "Lvly_feat._G._Curtis_-_Paper_Chasing.mp3  =>  happy\n",
      "Mafiyaan - Sukriti & Prakriti Kakar ft. MellowD.mp3  =>  happy\n",
      "Magenta_Riddim.mp3  =>  happy\n",
      "MERCER_-_BOSS_[OFFICIAL_MUSIC_VIDEO].mp3  =>  calm\n",
      "Millind Gaba_ NAZAR LAG JAYEGI Video Song _ Kamal(MP3_128K).mp3  =>  calm\n",
      "Nicky_Jam%2C_J._Balvin_-_X_EQUIS__Letra___Lyrics_.mp3  =>  happy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m     predictions\n\u001b[0;32m     53\u001b[0m     freq\u001b[38;5;241m.\u001b[39mappend(convertclasstoemotion(predictions))\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28mprint\u001b[39m(i,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m => \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "dir_list = os.listdir(path)\n",
    "for i in dir_list:\n",
    "    if(i[-1]=='3'):  #ending with mp3\n",
    "        loc=\"Music\\\\\"\n",
    "        loc+=i\n",
    "        \n",
    "        \"\"\"\n",
    "        data, sampling_rate = librosa.load(loc)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "        x = tf.expand_dims(mfccs, axis=1)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        #print(x)\n",
    "\n",
    "        predictions = a.predict_classes(x)\n",
    "        predictions\n",
    "        print(convertclasstoemotion(predictions))\n",
    "        \"\"\"\n",
    "        freq=[]\n",
    "        sound = AudioSegment.from_mp3(loc)\n",
    "        #duration calculation function\n",
    "        sound.duration_seconds == (len(sound) / 1000.0)\n",
    "        #print(sound.duration_seconds)\n",
    "        tim=sound.duration_seconds/100\n",
    "\n",
    "        for j in range(int(tim)):\n",
    "            offset=j*100+4  #After  4sec\n",
    "            #Selecting Portion we want to cut\n",
    "            StrtMin = offset//60\n",
    "            StrtSec = offset%60\n",
    "            offset+=10\n",
    "            EndMin = offset//60\n",
    "            EndSec = offset%60\n",
    "\n",
    "            # Time to milliseconds conversion\n",
    "            StrtTime = StrtMin*60*1000+StrtSec*1000\n",
    "            EndTime = StrtMin*60*1000+EndSec*1000\n",
    "\n",
    "            # Opening file and extracting portion of it\n",
    "            extract = sound[StrtTime:EndTime]\n",
    "\n",
    "            # Saving file in required location\n",
    "            extract.export(\"Music\\portion.mp3\", format=\"mp3\")\n",
    "            data, sampling_rate = librosa.load('Music\\portion.mp3')\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "            x = tf.expand_dims(mfccs, axis=1)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            #print(x)\n",
    "\n",
    "            predictions = a.predict_classes(x)\n",
    "            predictions\n",
    "            freq.append(convertclasstoemotion(predictions))\n",
    "        print(i,\" => \", max(freq,key=freq.count))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1e6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114c8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f78b8a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calm\n"
     ]
    }
   ],
   "source": [
    "data, sampling_rate = librosa.load('Music\\portion.mp3')\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "\n",
    "x = tf.expand_dims(mfccs, axis=1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#print(x)\n",
    "\n",
    "predictions = a.predict_classes(x)\n",
    "predictions\n",
    "print(convertclasstoemotion(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "932547f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertclasstoemotion(pred):\n",
    "    label_conversion = {'0': 'neutral',\n",
    "                            '1': 'calm',\n",
    "                            '2': 'happy',\n",
    "                            '3': 'sad',\n",
    "                            '4': 'angry',\n",
    "                            '5': 'fearful',\n",
    "                            '6': 'disgust',\n",
    "                            '7': 'surprised'}\n",
    "\n",
    "    for key, value in label_conversion.items():\n",
    "        if int(key) == pred:\n",
    "            label = value\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9d97279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_silent(data):\n",
    "    # Returns 'True' if below the 'silent' threshold\n",
    "    return max(data) < 100\n",
    "emotions = {\n",
    "    0 : 'neutral',\n",
    "    1 : 'calm',\n",
    "    2 : 'happy',\n",
    "    3 : 'sad',\n",
    "    4 : 'angry',\n",
    "    5 : 'fearful',\n",
    "    6 : 'disgust',\n",
    "    7 : 'suprised'   \n",
    "}\n",
    "emo_list = list(emotions.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c379f1",
   "metadata": {},
   "source": [
    "# Real Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ad697ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "neutral\n",
      "** session ended\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "RATE = 24414\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 7.1\n",
    "\n",
    "FORMAT = pyaudio.paInt32\n",
    "CHANNELS = 1\n",
    "WAVE_OUTPUT_FILE = \"output.wav\"\n",
    "# Open an input channel\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
    "data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
    "\n",
    "# SESSION START\n",
    "print(\"** session started\")\n",
    "total_predictions = [] # A list for all predictions in the session.\n",
    "tic = time.perf_counter()\n",
    "\n",
    "\n",
    "while is_silent(data) == False:\n",
    "    print(\"* recording...\")\n",
    "    frames = [] \n",
    "    data = np.nan # Reset 'data' variable.\n",
    "\n",
    "    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
    "    #print(timesteps)\n",
    "\n",
    "    # Insert frames to 'output.wav'.\n",
    "    for i in range(0, timesteps):\n",
    "        data = array('l', stream.read(CHUNK)) \n",
    "        frames.append(data)\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(\"* done recording\")\n",
    "    \n",
    "    data, sampling_rate = librosa.load('03-01-01-01-01-01-09.wav')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "\n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclasstoemotion(predictions))\n",
    "   \n",
    "    # Define the last 2 seconds sequence.\n",
    "    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n",
    "                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n",
    "                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n",
    "                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n",
    "                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n",
    "                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n",
    "                                                               axis =0)) , dtype = 'b')\n",
    "    \n",
    "    if is_silent(last_frames): # If the last 2 sec=onds are silent, end the session.\n",
    "        break\n",
    "    \n",
    "# SESSION END        \n",
    "toc = time.perf_counter()\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "wf.close()\n",
    "print('** session ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29454c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "happy\n",
      "** session ended\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "RATE = 24414\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 7.1\n",
    "\n",
    "FORMAT = pyaudio.paInt32\n",
    "CHANNELS = 1\n",
    "WAVE_OUTPUT_FILE = \"output.wav\"\n",
    "# Open an input channel\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
    "data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
    "\n",
    "# SESSION START\n",
    "print(\"** session started\")\n",
    "total_predictions = [] # A list for all predictions in the session.\n",
    "tic = time.perf_counter()\n",
    "\n",
    "\n",
    "while is_silent(data) == False:\n",
    "    print(\"* recording...\")\n",
    "    frames = [] \n",
    "    data = np.nan # Reset 'data' variable.\n",
    "\n",
    "    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
    "    #print(timesteps)\n",
    "\n",
    "    # Insert frames to 'output.wav'.\n",
    "    for i in range(0, timesteps):\n",
    "        data = array('l', stream.read(CHUNK)) \n",
    "        frames.append(data)\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(\"* done recording\")\n",
    "    \n",
    "    data, sampling_rate = librosa.load('03-01-02-01-02-02-13.wav')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "\n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclastoemotion(predictions))\n",
    "   \n",
    "    # Define the last 2 seconds sequence.\n",
    "    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n",
    "                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n",
    "                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n",
    "                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n",
    "                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n",
    "                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n",
    "                                                               axis =0)) , dtype = 'b')\n",
    "    \n",
    "    if is_silent(last_frames): # If the last 2 sec=onds are silent, end the session.\n",
    "        break\n",
    "    \n",
    "# SESSION END        \n",
    "toc = time.perf_counter()\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "wf.close()\n",
    "print('** session ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "611150e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "sad\n",
      "** session ended\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "RATE = 24414\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 7.1\n",
    "\n",
    "FORMAT = pyaudio.paInt32\n",
    "CHANNELS = 1\n",
    "WAVE_OUTPUT_FILE = \"output.wav\"\n",
    "# Open an input channel\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
    "data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
    "\n",
    "# SESSION START\n",
    "print(\"** session started\")\n",
    "total_predictions = [] # A list for all predictions in the session.\n",
    "tic = time.perf_counter()\n",
    "\n",
    "\n",
    "while is_silent(data) == False:\n",
    "    print(\"* recording...\")\n",
    "    frames = [] \n",
    "    data = np.nan # Reset 'data' variable.\n",
    "\n",
    "    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
    "    #print(timesteps)\n",
    "\n",
    "    # Insert frames to 'output.wav'.\n",
    "    for i in range(0, timesteps):\n",
    "        data = array('l', stream.read(CHUNK)) \n",
    "        frames.append(data)\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(\"* done recording\")\n",
    "    \n",
    "    data, sampling_rate = librosa.load('03-01-08-01-02-02-05.wav')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "\n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclasstoemotion(predictions))\n",
    "   \n",
    "    # Define the last 2 seconds sequence.\n",
    "    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n",
    "                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n",
    "                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n",
    "                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n",
    "                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n",
    "                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n",
    "                                                               axis =0)) , dtype = 'b')\n",
    "    \n",
    "    if is_silent(last_frames): # If the last 2 sec=onds are silent, end the session.\n",
    "        break\n",
    "    \n",
    "# SESSION END        \n",
    "toc = time.perf_counter()\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "wf.close()\n",
    "print('** session ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3612160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** session started\n",
      "* recording...\n",
      "* done recording\n",
      "angry\n",
      "** session ended\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initialize variables\n",
    "RATE = 24414\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 7.1\n",
    "\n",
    "FORMAT = pyaudio.paInt32\n",
    "CHANNELS = 1\n",
    "WAVE_OUTPUT_FILE = \"output.wav\"\n",
    "# Open an input channel\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
    "data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
    "\n",
    "# SESSION START\n",
    "print(\"** session started\")\n",
    "total_predictions = [] # A list for all predictions in the session.\n",
    "tic = time.perf_counter()\n",
    "\n",
    "\n",
    "while is_silent(data) == False:\n",
    "    print(\"* recording...\")\n",
    "    frames = [] \n",
    "    data = np.nan # Reset 'data' variable.\n",
    "\n",
    "    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
    "    #print(timesteps)\n",
    "\n",
    "    # Insert frames to 'output.wav'.\n",
    "    for i in range(0, timesteps):\n",
    "        data = array('l', stream.read(CHUNK)) \n",
    "        frames.append(data)\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(\"* done recording\")\n",
    "    \n",
    "    data, sampling_rate = librosa.load('03-01-05-01-02-02-14.wav')\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=40).T, axis=0)\n",
    "\n",
    "    x = tf.expand_dims(mfccs, axis=1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #print(x)\n",
    "\n",
    "    predictions = a.predict_classes(x)\n",
    "    predictions\n",
    "    print(convertclasstoemotion(predictions))\n",
    "   \n",
    "    # Define the last 2 seconds sequence.\n",
    "    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n",
    "                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n",
    "                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n",
    "                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n",
    "                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n",
    "                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n",
    "                                                               axis =0)) , dtype = 'b')\n",
    "    \n",
    "    if is_silent(last_frames): # If the last 2 sec=onds are silent, end the session.\n",
    "        break\n",
    "    \n",
    "# SESSION END        \n",
    "toc = time.perf_counter()\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "wf.close()\n",
    "print('** session ended')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab754ef4",
   "metadata": {},
   "source": [
    "# Part 2: \n",
    "Classifying based on hindi textual lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d723b59",
   "metadata": {},
   "source": [
    "# Continuing in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9f243dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==3.1.0a0\n",
      "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "     -------------------------------------- 55.1/55.1 kB 477.2 kB/s eta 0:00:00\n",
      "Collecting hstspreload\n",
      "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 485.3 kB/s eta 0:00:00\n",
      "Collecting rfc3986<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.12.7)\n",
      "Collecting idna==2.*\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "     -------------------------------------- 58.8/58.8 kB 783.4 kB/s eta 0:00:00\n",
      "Collecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     ------------------------------------ 133.4/133.4 kB 562.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
      "Collecting httpcore==0.9.*\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "     -------------------------------------- 53.6/53.6 kB 688.4 kB/s eta 0:00:00\n",
      "Collecting h2==3.*\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "     -------------------------------------- 65.0/65.0 kB 583.0 kB/s eta 0:00:00\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16376 sha256=0252282af3dc64cf1813c5a78247dcd24fc683fc7069f86d75696bc16597d9a5\n",
      "  Stored in directory: c:\\users\\ssd\\appdata\\local\\pip\\cache\\wheels\\e1\\a1\\42\\8f744c366846e6c1ea9efe2293260e1f9614a70251076eeef8\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-3.4 rfc3986-1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiohttp 3.8.3 requires charset-normalizer<3.0,>=2.0, but you have charset-normalizer 3.1.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a053a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep_translator\n",
      "  Downloading deep_translator-1.10.1-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from deep_translator) (2.28.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from deep_translator) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.26.15)\n",
      "Installing collected packages: deep_translator\n",
      "Successfully installed deep_translator-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b9f17ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentimentNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "     ------------------------------------ 126.0/126.0 kB 528.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from vaderSentiment) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from requests->vaderSentiment) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from requests->vaderSentiment) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc63d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codecs provides access to the internal Python codec registry\n",
    "\n",
    "import codecs\n",
    " \n",
    "# This is to translate the text from Hindi to English\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    " \n",
    "# This is to analyse the sentiment of text\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c702e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c09bb4",
   "metadata": {},
   "source": [
    "# Trying with hindi lyrics songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b0072ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[\"चाँद ने कुछ कहा, रात ने कुछ सुना तू भी सुन बेखबर, प्यार कर, प्यार कर आई है चाँदनी, मुझसे कहने यही मेरी गली, मेरे घर, प्यार कर, प्यार कर क्या कहूँ क्या पता, बात क्या हो गई दिल्लगी ये मेरे, साथ क्या हो गई इक इशारा है ये, दिल पुकारा है ये इससे चुरा ना नजर प्यार कर, प्यार कर...\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b947be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "hinEng=\"\"\n",
    "for sentence in a:\n",
    "    translated_text = GoogleTranslator(source='auto', target='en').translate(sentence)\n",
    "    hinEng+=translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c85721ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The moon said something, the night heard something, you also listen unaware, love me, love me, this is my street, my home What happened with you, this is a gesture, the heart has called out to it, don't steal your eyes, love, love...\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinEng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f43cf061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting text2emotion\n",
      "  Downloading text2emotion-0.0.5-py3-none-any.whl (57 kB)\n",
      "     -------------------------------------- 57.8/57.8 kB 609.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from text2emotion) (3.8.1)\n",
      "Collecting emoji>=0.6.0\n",
      "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
      "     ------------------------------------ 240.9/240.9 kB 527.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib in c:\\users\\ssd\\appdata\\roaming\\python\\python39\\site-packages (from nltk->text2emotion) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from nltk->text2emotion) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from nltk->text2emotion) (4.65.0)\n",
      "Requirement already satisfied: click in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from nltk->text2emotion) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (from click->nltk->text2emotion) (0.4.6)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234917 sha256=701319b112cf7c25d76029998f0c690485cbba065369f4df95018910405204b6\n",
      "  Stored in directory: c:\\users\\ssd\\appdata\\local\\pip\\cache\\wheels\\34\\1c\\15\\553c4ad364178bab0c80f1fec134dec07ad6f1afbf15e360c1\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, text2emotion\n",
      "Successfully installed emoji-2.2.0 text2emotion-0.0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#Install package using pip\n",
    "!pip install text2emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f5105213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "565d7e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji==1.7 in c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages (1.7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-contrib-python (c:\\users\\ssd\\anaconda3\\envs\\x360spctregpu\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji==1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e18da",
   "metadata": {},
   "source": [
    "# For the part 4, \n",
    "After installaiton, Combining it. \n",
    "\n",
    "To have have complete data, for each songs, thereby recommending the songs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
