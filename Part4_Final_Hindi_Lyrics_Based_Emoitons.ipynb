{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hindi Songs classification using NLP, and music recommendation\n",
        "Here, we are firstly classifying the songs based on their lyrics, then combining it with the Part3 model's result to get the most accuracy result. \n"
      ],
      "metadata": {
        "id": "p-pkidAcH7df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7Gk2kBBCaFW",
        "outputId": "0686a20d-df71-4619-ca7a-fae489650135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.12.7)\n",
            "Collecting chardet==3.*\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hstspreload\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.*\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16368 sha256=8c5e8eca2b2c1a040035215e2630644db06fc2fda0b945caa35def59625d6963\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/e1/6c/5137bc3f35aa130deea71575e165cc4f4f0680a88f3d90a636\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, sniffio, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "Successfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0 sniffio-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install deep_translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z97NoBXCcus",
        "outputId": "ebb6f6d4-f41f-4fd4-eaae-c78c03d9e055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.10.1-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from deep_translator) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.9/dist-packages (from deep_translator) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.12)\n",
            "Installing collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTA0Jw8cCaCK",
        "outputId": "0784db29-a372-4017-cb08-4183001149bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from vaderSentiment) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->vaderSentiment) (1.26.15)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# codecs provides access to the internal Python codec registry\n",
        "\n",
        "import codecs\n",
        " \n",
        "# This is to translate the text from Hindi to English\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        " \n",
        "# This is to analyse the sentiment of text\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        " "
      ],
      "metadata": {
        "id": "xPR-zIbRCaAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from googletrans import Translator"
      ],
      "metadata": {
        "id": "slG9aoOeCz_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[\"गोवा की यात्रा बहुत अच्छी रही।\",\"समुद्र तट बहुत गर्म थे।\",\"मुझे समुद्र तट पर खेलने में बहुत मजा आया।\",\"मेरी बेटी बहुत गुस्से में थी।\"]\n",
        "hinEng=\"\"\n",
        "for sentence in sentences:\n",
        "\n",
        "    translated_text = GoogleTranslator(source='auto', target='en').translate(sentence)\n",
        "    hinEng+=translated_text\n",
        "    #print(translated_text)\n",
        "\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "    sentiment_dict = analyzer.polarity_scores(translated_text)\n",
        "\n",
        "     \n",
        "\n",
        "    print(\"\\nTranslated Sentence=\",translated_text, \"\\nDictionary=\",sentiment_dict)\n",
        "\n",
        "    if sentiment_dict['compound'] >= 0.05 :\n",
        "\n",
        "            print(\"It is a Positive Sentence\")\n",
        "\n",
        "              \n",
        "\n",
        "    elif sentiment_dict['compound'] <= - 0.05 :\n",
        "\n",
        "            print(\"It is a Negative Sentence\")      \n",
        "\n",
        "    else :    \n",
        "\n",
        "           print(\"It is a Neutral Sentence\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5A3JYXfC0B8",
        "outputId": "49ef0342-61f1-4b61-e2f3-b0ea7b4c9db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Translated Sentence= Goa trip was great. \n",
            "Dictionary= {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'compound': 0.6249}\n",
            "It is a Positive Sentence\n",
            "\n",
            "Translated Sentence= The beaches were very hot. \n",
            "Dictionary= {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "It is a Neutral Sentence\n",
            "\n",
            "Translated Sentence= I really enjoyed playing on the beach. \n",
            "Dictionary= {'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'compound': 0.688}\n",
            "It is a Positive Sentence\n",
            "\n",
            "Translated Sentence= My daughter was very angry. \n",
            "Dictionary= {'neg': 0.473, 'neu': 0.527, 'pos': 0.0, 'compound': -0.5563}\n",
            "It is a Negative Sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hindi Text: \",)\n",
        "hinEng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "0ou-J46LC0Ei",
        "outputId": "56ec7077-266d-4816-ac0d-d0156d849441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hindi Text: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Goa trip was great.The beaches were very hot.I really enjoyed playing on the beach.My daughter was very angry.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying with Hindi Songs"
      ],
      "metadata": {
        "id": "ohtZPne1C8Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=[\"चाँद ने कुछ कहा, रात ने कुछ सुना तू भी सुन बेखबर, प्यार कर, प्यार कर आई है चाँदनी, मुझसे कहने यही मेरी गली, मेरे घर, प्यार कर, प्यार कर क्या कहूँ क्या पता, बात क्या हो गई दिल्लगी ये मेरे, साथ क्या हो गई इक इशारा है ये, दिल पुकारा है ये इससे चुरा ना नजर प्यार कर, प्यार कर...\"]"
      ],
      "metadata": {
        "id": "nephyGwCC7Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hinEng=\"\"\n",
        "for sentence in a:\n",
        "    translated_text = GoogleTranslator(source='auto', target='en').translate(sentence)\n",
        "    hinEng+=translated_text\n",
        "    #print(translated_text)"
      ],
      "metadata": {
        "id": "uyQpmTs2C0HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hinEng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "LCfZfTaXCZ_M",
        "outputId": "5b518f0e-55f2-4b7d-9270-078857af9387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The moon said something, the night heard something, you also listen unaware, love me, love me, this is my street, my home What happened with you, this is a gesture, the heart has called out to it, don't steal your eyes, love, love...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbpCy6hexDiq",
        "outputId": "c7342c25-4647-495c-f3fc-f547f96ef3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting text2emotion\n",
            "  Downloading text2emotion-0.0.5-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from text2emotion) (3.8.1)\n",
            "Collecting emoji>=0.6.0\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->text2emotion) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->text2emotion) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->text2emotion) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->text2emotion) (4.65.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=141dd7423db317d42206beb5713f126de53586623be9290a8d77f8b468675ff0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/b8/0f/f580817231cbf59f6ade9fd132ff60ada1de9f7dc85521f857\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, text2emotion\n",
            "Successfully installed emoji-2.2.0 text2emotion-0.0.5\n"
          ]
        }
      ],
      "source": [
        "#Install package using pip\n",
        "!pip install text2emotion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall emoji\n",
        "!pip install emoji==1.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgPWGWU8yMT5",
        "outputId": "6f91364f-c8e5-4221-8fb6-bed929ef00d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: emoji 2.2.0\n",
            "Uninstalling emoji-2.2.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.9/dist-packages/emoji-2.2.0.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/emoji/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled emoji-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji==1.7\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171048 sha256=ed14fd10063500d9bb20330e957463f5ea0bd81a4d1616f40b31672679999804\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/7a/e9/22dd0515e1bad255e51663ee513a2fa839c95934c5fc301090\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the modules\n",
        "import text2emotion as te"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csj_VqS6xO3t",
        "outputId": "4463d6bc-6561-4af8-d1d2-774001f919ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I was asked to sign a third party contract a week out from stay. If it wasn't an 8 person group that took a lot of wrangling I would have cancelled the booking straight away. Bathrooms - there are no stand alone bathrooms. Please consider this - you have to clear out the main bedroom to use that bathroom. Other option is you walk through a different bedroom to get to its en-suite. Signs all over the apartment - there are signs everywhere - some helpful - some telling you rules. Perhaps some people like this but It negatively affected our enjoyment of the accommodation. Stairs - lots of them - some had slightly bending wood which caused a minor injury.\""
      ],
      "metadata": {
        "id": "TWvHUOuQxU0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Call to the function\n",
        "te.get_emotion(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwV_2QYOxYvW",
        "outputId": "c0fc5d33-f04f-4106-e3f5-22b44230d456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Happy': 0.05, 'Angry': 0.16, 'Surprise': 0.05, 'Sad': 0.32, 'Fear': 0.42}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"In your love, in your love, my heart wants to get wet, I got drunk, I fell in love with you, who once got drunk, everything has become old;\"\n",
        "te.get_emotion(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tltjs3SyyJT",
        "outputId": "43f6e0ec-ec36-471d-c1d6-11ee919e050c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Happy': 0.6, 'Angry': 0.2, 'Surprise': 0.0, 'Sad': 0.2, 'Fear': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Keymax = max(zip(te.get_emotion(text1).values(), te.get_emotion(text1).keys()))[1]\n",
        "print(Keymax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O9j7qo8yyRy",
        "outputId": "d16fb02c-2d9d-4472-d23d-4ea6fe053ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1=hinEng\n",
        "Keymax = max(zip(te.get_emotion(text1).values(), te.get_emotion(text1).keys()))[1]\n",
        "print(Keymax)"
      ],
      "metadata": {
        "id": "V9rfJ6HdyyUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528c690f-e3a2-4366-92d0-c478b1d35d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUbtIDRfFLUT",
        "outputId": "987a6b46-e69a-478d-de87-eef44333a1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"/content/drive/MyDrive/VIT/HindiMusic/1_ChannaMereya.txt\",\"r\")"
      ],
      "metadata": {
        "id": "wIVfMThTyyaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f=file1.readlines()"
      ],
      "metadata": {
        "id": "dBUEEmzHyyda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "  \n",
        "# Folder Path\n",
        "path = r\"/content/drive/MyDrive/VIT/HindiMusic\"\n",
        "  \n",
        "# Change the directory\n",
        "os.chdir(path)\n",
        "  \n",
        "# Read text File"
      ],
      "metadata": {
        "id": "YdJumx1MKfbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "CSldtPfqLf_r",
        "outputId": "69158d6f-57a4-468c-e8be-d58ff60ae943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'इश्क मेरे यारा\\nओ ओ मेरे यारा\\nतू कर ले दोबारा\\nकर ले दोबारा\\nबस इक बार में ही\\nइक बार में ही\\nभरे ना दिल बेचारा\\nभरे ना दिल बेचारा\\nसंग रहने के शाम सवेरे\\nक्या करने हैं वादे बथेरे\\nहै ज़िंदगानी अगर चार दिन की\\nतो लेने ही क्यों सात फेरे\\nतूने जवानी में सीखा\\nना जाने कहां का सलीका\\nजो पहले ही ब्रेक अप में\\nदिल ने तेरे गिव अप कर दिया\\nएक बार ही किया तो यारों\\nप्यार क्या किया\\nएक बार ही किया तो यारों\\nप्यार क्या किया\\nप्यार होता होता होता\\nकई बार है\\nसिर्फ एक पे किया तो\\nदिल निसार क्या किया\\nसिर्फ एक पे किया तो\\nदिल निसार क्या किया\\nप्यार होता होता होता\\nकई बार है\\nप्यार होता होता होता\\nकई बार है\\nम्यूजिक…\\nपहली मोहब्बत में तो\\nलगता यही है डार्लिंग\\nमर जाऊंगा जो मुझको\\nये ना मिली\\nअगली दफा मोहब्बत\\nहोती है तो लगता है\\nये वाली मुझको पहले\\nक्यूँ ना मिली\\nवो दिल क्या भला\\nजो टुटा ना कभी\\nपहली दफा चोट खाके\\nक्यूँ दिल को लगाना ही छोड़ें\\nसब कुछ मोहब्बत में\\nचलता है तो क्यूँ ना\\nदो चार दिल हम भी तोड़ें\\nतूने जवानी में सीखा\\nना जाने कहां का सलीका\\nजो पहले ही ब्रेक अप में\\nदिल ने तेरे गिव अप कर दिया\\nएक बार ही किया तो यारों\\nप्यार क्या किया\\nएक बार ही किया तो यारों\\nप्यार क्या किया\\nप्यार होता होता होता\\nकई बार है\\nसिर्फ एक पे किया तो\\nदिल निसार क्या किया\\nसिर्फ एक पे किया तो\\nदिल निसार क्या किया\\nप्यार होता होता होता\\nकई बार है\\nप्यार होता होता होता\\nकई बार है\\nलेट्स गौ लेट्स गौ\\nतैनू प्यार दी लोड ए\\nचाहिदा किन्ना वे\\nबोलो बोलो\\nकदी दस्सदे यार नु\\nइन्ना इन्ना वे\\nसे नो से नो\\nतैनू प्यार दी लोड ए\\nचाहिदा किन्ना वे\\nबोलो बोलो\\nत्वाड्डी खिदमत विच हाजिर\\nए लो  ए लो\\nप्यार होता होता होता\\nकई बार है'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVG-Gx-FNAee",
        "outputId": "11623a85-bdd2-4712-e500-0090314ad586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "love my friend\n",
            "oh oh my friend\n",
            "you do it again\n",
            "do it again\n",
            "just once in a while\n",
            "at once\n",
            "Don't fill your heart poor\n",
            "Don't fill your heart poor\n",
            "morning and evening to be together\n",
            "What are the promises to be made?\n",
            "If life is of four days\n",
            "So why take seven rounds\n",
            "you learned when you were young\n",
            "don't know where\n",
            "who is already in break up\n",
            "heart gave you up\n",
            "done it once guys\n",
            "what did love do\n",
            "done it once guys\n",
            "what did love do\n",
            "would have been love\n",
            "is many times\n",
            "if done only on one\n",
            "What did Dil Nisar do\n",
            "if done only on one\n",
            "What did Dil Nisar do\n",
            "would have been love\n",
            "is many times\n",
            "would have been love\n",
            "is many times\n",
            "Music…\n",
            "in first love\n",
            "it seems darling\n",
            "i will die\n",
            "didn't get it\n",
            "next time love\n",
            "If it happens then it seems\n",
            "this one to me first\n",
            "why didn't you get\n",
            "what is that heart\n",
            "that never broke\n",
            "hurt for the first time\n",
            "why leave your heart alone\n",
            "all in love\n",
            "it works then why not\n",
            "We will also break two or four hearts\n",
            "you learned when you were young\n",
            "don't know where\n",
            "who is already in break up\n",
            "heart gave you up\n",
            "done it once guys\n",
            "what did love do\n",
            "done it once guys\n",
            "what did love do\n",
            "would have been love\n",
            "is many times\n",
            "if done only on one\n",
            "What did Dil Nisar do\n",
            "if done only on one\n",
            "What did Dil Nisar do\n",
            "would have been love\n",
            "is many times\n",
            "would have been love\n",
            "is many times\n",
            "Let's Go Let's Go\n",
            "tainu pyar di load a\n",
            "should we\n",
            "Speak up\n",
            "kadi dasde yaar nu\n",
            "inna inna ve\n",
            "from no to no\n",
            "tainu pyar di load a\n",
            "should we\n",
            "Speak up\n",
            "Twaddi Khidmat Witch Spot\n",
            "a lo a lo\n",
            "would have been love\n",
            "is many times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hinEng=\"\"\n",
        "for sentence in a:\n",
        "  if('\\n' in sentence):\n",
        "    continue\n",
        "    translated_text = GoogleTranslator(source='auto', target='en').translate(sentence)\n",
        "    if(translated_text==None):\n",
        "      continue\n",
        "    hinEng+=translated_text\n",
        "    #print(translated_text)\n",
        "Keymax = max(zip(te.get_emotion(hinEng).values(), te.get_emotion(hinEng).keys()))[1]\n",
        "print(file,Keymax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqO9zCpQMWOv",
        "outputId": "288cc6c3-abb9-41e3-c0b0-b619031205c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".ipynb_checkpoints Surprise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir():\n",
        "  print(file)\n",
        "  file_path = f\"{path}/{file}\"\n",
        "  print(file_path)"
      ],
      "metadata": {
        "id": "Kdx8MLDYyyjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aef0bfe-c6c3-4792-aeda-8e3a6b543907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2_MeriKahani.txt\n",
            "/content/drive/MyDrive/VIT/HindiMusic/2_MeriKahani.txt\n",
            "1_ChannaMereya.txt\n",
            "/content/drive/MyDrive/VIT/HindiMusic/1_ChannaMereya.txt\n",
            "6_ChaandPyarKar.txt\n",
            "/content/drive/MyDrive/VIT/HindiMusic/6_ChaandPyarKar.txt\n",
            "4_JhoomeJoPathan.txt\n",
            "/content/drive/MyDrive/VIT/HindiMusic/4_JhoomeJoPathan.txt\n",
            "3_JhoomeJoPathaan.txt\n",
            "/content/drive/MyDrive/VIT/HindiMusic/3_JhoomeJoPathaan.txt\n",
            "5_Pyarhota kayibaarhai.txt\n",
            "/content/drive/MyDrive/VIT/HindiMusic/5_Pyarhota kayibaarhai.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# iterate through all file\n",
        "for file in os.listdir():\n",
        "    # Check whether file is in text format or not\n",
        "    if file.endswith(\".txt\"):\n",
        "        file_path = f\"{path}/{file}\"\n",
        "        # call read text file function\n",
        "        #print(read_text_file(file_path))\n",
        "        with open(file_path, 'r') as f:\n",
        "          a=f.read()\n",
        "        #print(a)\n",
        "        translated_text = GoogleTranslator(source='auto', target='en').translate(a)\n",
        "        Keymax = max(zip(te.get_emotion(translated_text).values(), te.get_emotion(translated_text).keys()))[1]\n",
        "        print(file,Keymax)\n"
      ],
      "metadata": {
        "id": "6M5IthxzyygR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91454fe7-1dac-484f-89e8-77db8709340e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2_MeriKahani.txt Sad\n",
            "1_ChannaMereya.txt Happy\n",
            "6_ChaandPyarKar.txt Happy\n",
            "4_JhoomeJoPathan.txt Fear\n",
            "3_ArereArereKyaHua.txt Sad\n",
            "5_Pyarhota kayibaarhai.txt Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through all file\n",
        "for file in os.listdir():\n",
        "    # Check whether file is in text format or not\n",
        "    if file.endswith(\".txt\"):\n",
        "        file_path = f\"{path}/{file}\"\n",
        "        # call read text file function\n",
        "        #print(read_text_file(file_path))\n",
        "        with open(file_path, 'r') as f:\n",
        "          a=f.read()\n",
        "        #print(a)\n",
        "        translated_text = GoogleTranslator(source='auto', target='en').translate(a)\n",
        "        Keymax = max(zip(te.get_emotion(translated_text).values(), te.get_emotion(translated_text).keys()))[1]\n",
        "        print(file,Keymax)"
      ],
      "metadata": {
        "id": "hi0ArqIbyylN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f5c2cc-766d-4d41-b3ab-e8251cc7bdb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2_MeriKahani.txt Sad\n",
            "1_ChannaMereya.txt Happy\n",
            "6_ChaandPyarKar.txt Happy\n",
            "4_JhoomeJoPathan.txt Fear\n",
            "3_ArereArereKyaHua.txt Sad\n",
            "5_Pyarhota kayibaarhai.txt Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion: \n",
        "* After classifying the emotions for the hindi songs based on lyrics(NLP), and the audio model's resutls, we will add the song names, and the nlp, audio results for the emotion classification. \n",
        "* Then, based on user's choice, prioritizing NLP/Audio results, and annotatng the songs(Like, for each song in the dataframe, adding another column with the emotions)\n",
        "* Finally, using our audio model, analysing the user's emotion in real time, and calssifying hir/her emotion, and based on that, using the CBF(And, kmeans algo, some other algorithm for recommending) recommendation algorithm, recommending a music which matches the emotion of the saved data. \n",
        "* This emotion correlation will be custom based on user's taste, like if the user's predicted emotion is sad, then it'll predict happy songs, similary, \n",
        "* For the future implementation, we are also planning to add the time feature, like if it's night time, many users prefer LoFi songs, of sad emotion, so we can also add time constraing.\n",
        "* This can also be used for comparative study of NLP vs. Audio, which is better in predicting emotions. Thereby conclusing which is better in using the music emotions."
      ],
      "metadata": {
        "id": "CxgMkJszHDJ-"
      }
    }
  ]
}